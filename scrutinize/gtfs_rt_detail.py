from abc import ABC
from abc import abstractmethod
from typing import Optional, List, Tuple

import pyarrow

def flatten_table_schema(table: pyarrow.table) -> pyarrow.table:
    """flatten pyarrow table if struct column type exists"""
    for field in table.schema:
        if str(field.type).startswith("struct"):
            return flatten_table_schema(table.flatten())
    return table

class GTFSRTDetail(ABC):
    """
    Abstract Base Class for all GTFSRTDetail implementations.

    GTFSRTDetail classes must implement all methods and properties that are
    defined.
    """

    def transform_for_write(self, table: pyarrow.table) -> pyarrow.table:
        """modify table schema before write to parquet"""
        return flatten_table_schema(table)

    @property
    @abstractmethod
    def partition_column(self) -> str:
        """Column used to partition parquet files for this config"""

    @property
    @abstractmethod
    def import_schema(self) -> pyarrow.schema:
        """Get the import schema for the parquet table generated by this config"""

    @property
    def table_sort_order(self) -> Optional[List[Tuple[str, str]]]:
        """
        Provide list of fields to sort pyarrow table before writing to parquet

        table_sort_order should be configured to optimize parquet file size
        when writing to disk

        Currently specified sort orders were determined by a small amount of experimentation

        TODO: perform additional experiments to optimize sort order of all parquet file types  # pylint: disable=fixme
        """
        return None



def flatten_table_schema(table: pyarrow.table) -> pyarrow.table:
    """flatten pyarrow table if struct column type exists"""
    for field in table.schema:
        if str(field.type).startswith("struct"):
            return flatten_table_schema(table.flatten())
    return table
